{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I uploaded the images as zipped file and now I will unzip it by \n",
    "import zipfile\n",
    "with zipfile.ZipFile('images/images.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it created jpg folder,  it unzipped the file and create the images inside jpg folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will divide the images in categories and create folder per category\n",
    "# the category will be like category name-category id\n",
    "# the categories are stored in categories.txt file \n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "categories_file_path = 'categories.txt'\n",
    "# read category names from categories.txt file\n",
    "categories = open(categories_file_path, \"r\")\n",
    "category_names = categories.read().split('\\n')\n",
    "category_paths = []\n",
    "\n",
    "for i in range(len(category_names)):\n",
    "    name = category_names[i] + \"-\" + str(i + 1)\n",
    "    category_path=os.path.join('dataset', name)\n",
    "    category_paths.append(category_path)\n",
    "    if not os.path.exists(category_path):\n",
    "        os.makedirs(category_path)\n",
    "\n",
    "images_info=[]\n",
    "with open('imagelabels.csv', mode='r') as read_csv:\n",
    "    for image in read_csv:\n",
    "        images_info.append(image.split())\n",
    "\n",
    "# copy the images to the new folder that we created depend on each image category        \n",
    "images_path = 'images/jpg'\n",
    "\n",
    "for image in os.listdir(images_path):\n",
    "    image_name = image.split('.')[0]\n",
    "    image_number = image_name.split('_')[1]\n",
    "    image_num = int(image_number)\n",
    "    category_id = images_info[image_num - 1]\n",
    "    image_path = category_paths[int(category_id[0])-1]\n",
    "    current_path=os.path.join(images_path,image)\n",
    "    new_path=os.path.join(image_path,image)\n",
    "    if not os.path.exists(new_path):\n",
    "        shutil.copyfile(current_path,new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of the images is 8189\n",
      "the number of the categories is 102\n"
     ]
    }
   ],
   "source": [
    "# to make sure that all the images transfered successfully we will print the number of the category folders and the number of the images\n",
    "\n",
    "images = 0\n",
    "categories = []\n",
    "for i in os.listdir('dataset'):\n",
    "    categories.append(i)\n",
    "    \n",
    "for n in categories:\n",
    "    for m in os.listdir('dataset/' + n):\n",
    "        images += 1\n",
    "print(\"the number of the images is \" + str(images))    \n",
    "print(\"the number of the categories is \" + str(len(categories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use GrabCut to segment the foreground from the bac ground of the image \n",
    "# GrabCut is an image segmentation method based on graph cuts.\n",
    "# the refrence of the algorithm that i will create on geeks for geeks website on \n",
    "# https://www.geeksforgeeks.org/python-foreground-extraction-in-an-image-using-grabcut-algorithm/\n",
    "\n",
    "\n",
    "# Python program to illustrate  \n",
    "# foreground extraction using \n",
    "# GrabCut algorithm \n",
    "   \n",
    "# organize imports \n",
    "import numpy as np \n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt \n",
    "   \n",
    "def image_segmentation(image_name):    \n",
    "    # path to input image specified and  \n",
    "    # image is loaded with imread command \n",
    "    image = cv2.imread(image_name) \n",
    "\n",
    "    # create a simple mask image similar \n",
    "    # to the loaded image, with the  \n",
    "    # shape and return type \n",
    "    mask = np.zeros(image.shape[:2], np.uint8) \n",
    "\n",
    "    # specify the background and foreground model \n",
    "    # using numpy the array is constructed of 1 row \n",
    "    # and 65 columns, and all array elements are 0 \n",
    "    # Data type for the array is np.float64 (default) \n",
    "    backgroundModel = np.zeros((1, 65), np.float64) \n",
    "    foregroundModel = np.zeros((1, 65), np.float64) \n",
    "\n",
    "    # define the Region of Interest (ROI) \n",
    "    # as the coordinates of the rectangle \n",
    "    # where the values are entered as \n",
    "    # (startingPoint_x, startingPoint_y, width, height) \n",
    "    # these coordinates are according to the input image \n",
    "    # it may vary for different images \n",
    "    height, width, _ = image.shape\n",
    "    # now we specify the rectangle of ROI\n",
    "    # we will use threshold as crop the image to be 12% in (top, down, left,right)\n",
    "    # I think it will be better \n",
    "    ROI_threshold=0.12\n",
    "    rectangle = (int(ROI_threshold * height) , int(ROI_threshold * width), \n",
    "                 int(height-(ROI_threshold * height)), int(width-(ROI_threshold * width))) \n",
    "\n",
    "    # apply the grabcut algorithm with appropriate \n",
    "    # values as parameters, number of iterations = 3  \n",
    "    # cv2.GC_INIT_WITH_RECT is used because \n",
    "    # of the rectangle mode is used  \n",
    "    cv2.grabCut(image, mask, rectangle,   \n",
    "                backgroundModel, foregroundModel, \n",
    "                3, cv2.GC_INIT_WITH_RECT) \n",
    "\n",
    "    # In the new mask image, pixels will  \n",
    "    # be marked with four flags  \n",
    "    # four flags denote the background / foreground  \n",
    "    # mask is changed, all the 0 and 2 pixels  \n",
    "    # are converted to the background \n",
    "    # mask is changed, all the 1 and 3 pixels \n",
    "    # are now the part of the foreground \n",
    "    # the return type is also mentioned, \n",
    "    # this gives us the final mask \n",
    "    mask2 = np.where((mask == 2)|(mask == 0), 0, 1).astype('uint8') \n",
    "\n",
    "    # The final mask is multiplied with  \n",
    "    # the input image to give the segmented image. \n",
    "    image = image * mask2[:, :, np.newaxis]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will go to the training data step but before that , \n",
    "# we need to segment all images and copy the segmented images into a new seperated folder to use them in the training \n",
    "import os\n",
    "\n",
    "segmented_dataset_folder='segmentation_data'\n",
    "\n",
    "# for each sub folder in dataset create a folder with same name but contains the segmented images\n",
    "for f in os.listdir('dataset'):\n",
    "    category_path=os.path.join('dataset',f)\n",
    "    segmented_folder=os.path.join(segmented_dataset_folder,f)\n",
    "    if not os.path.exists(segmented_folder):\n",
    "        os.makedirs(segmented_folder)\n",
    "    for img in os.listdir(category_path):\n",
    "        new_image_path=os.path.join(segmented_folder,img)\n",
    "        if not os.path.exists(new_image_path):\n",
    "            img_path=os.path.join(category_path,img)\n",
    "            segmented_image=image_segmentation(img_path)\n",
    "            cv2.imwrite(new_image_path,segmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will isolate the test images in two folders , one for the segmentation and one for non segmentation images\n",
    "# we will take 20% of the dataset for testing\n",
    "# first we will start with non segmentation test\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "non_seg_test_folder=\"non_segmentation_test\"\n",
    "if not os.path.exists(non_seg_test_folder):\n",
    "    os.makedirs(non_seg_test_folder)\n",
    "        \n",
    "for folder in os.listdir('dataset'):\n",
    "    category_path=os.path.join('dataset',folder)\n",
    "    test_folder_path=os.path.join(non_seg_test_folder,folder)\n",
    "    if not os.path.exists(test_folder_path):\n",
    "        os.makedirs(test_folder_path)\n",
    "    num_images=len(os.listdir(category_path))\n",
    "    number_of_tests=int((num_images/100)*20)\n",
    "    category_names=os.listdir(category_path)\n",
    "    list_randoms=[]\n",
    "    images_already_moved=False\n",
    "    if len(os.listdir(test_folder_path))>0:\n",
    "        images_already_moved=True\n",
    "    if not images_already_moved:\n",
    "        while True:\n",
    "            ran=random.randint(1,number_of_tests)\n",
    "            if ran not in list_randoms:\n",
    "                list_randoms.append(ran)\n",
    "            if len(list_randoms)==number_of_tests:\n",
    "                break\n",
    "                \n",
    "        for n in list_randoms:\n",
    "            image_path=os.path.join(category_path,category_names[n-1])\n",
    "            new_image_path=os.path.join(test_folder_path,category_names[n-1])\n",
    "            if not os.path.exists(new_image_path):\n",
    "                shutil.move(image_path,new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will start with the segmentation test\n",
    "# we will take 20% of the dataset for testing\n",
    "# first we will start with segmentation test\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "seg_test_folder=\"segmentation_test\"\n",
    "if not os.path.exists(seg_test_folder):\n",
    "    os.makedirs(seg_test_folder)\n",
    "        \n",
    "for folder in os.listdir('dataset'):\n",
    "    category_path=os.path.join('dataset',folder)\n",
    "    test_folder_path=os.path.join(seg_test_folder,folder)\n",
    "    if not os.path.exists(test_folder_path):\n",
    "        os.makedirs(test_folder_path)\n",
    "    num_images=len(os.listdir(category_path))\n",
    "    number_of_tests=int((num_images/100)*20)\n",
    "    category_names=os.listdir(category_path)\n",
    "    list_randoms=[]\n",
    "    images_already_moved=False\n",
    "    if len(os.listdir(test_folder_path))>0:\n",
    "        images_already_moved=True\n",
    "    if not images_already_moved:\n",
    "        while True:\n",
    "            ran=random.randint(1,number_of_tests)\n",
    "            if ran not in list_randoms:\n",
    "                list_randoms.append(ran)\n",
    "            if len(list_randoms)==number_of_tests:\n",
    "                break\n",
    "                \n",
    "        for n in list_randoms:\n",
    "            image_path=os.path.join(category_path,category_names[n-1])\n",
    "            new_image_path=os.path.join(test_folder_path,category_names[n-1])\n",
    "            if not os.path.exists(new_image_path):\n",
    "                shutil.move(image_path,new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I read a lot before starting and this is the link I got to read from \n",
    "# https://www.tensorflow.org/hub/tutorials/image_retraining\n",
    "# create folders and paramaters that we will need for our training\n",
    "from random import shuffle\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "lr = 0.02\n",
    "training_steps = 10000\n",
    "display_step = 10\n",
    "num_classes=102\n",
    "\n",
    "test_image_dir_with_segmentation=\"segmentation_test/\"\n",
    "test_image_dir_without_segmentation=\"non_segmentation_test/\"\n",
    "train_image_dir_with_segmentation=\"segmentation_data/\"\n",
    "train_image_dir_without_segmentation=\"dataset/\"\n",
    "\n",
    "output_graph_path_without_segmentation=\"model/retrained_graph_without_segmentation/\"\n",
    "if not os.path.exists(output_graph_path_without_segmentation):\n",
    "    os.makedirs(output_graph_path_without_segmentation)\n",
    "    \n",
    "output_graph_path_with_segmentation=\"model/retrained_graph_with_segmentation/\"\n",
    "if not os.path.exists(output_graph_path_with_segmentation):\n",
    "    os.makedirs(output_graph_path_with_segmentation)\n",
    "\n",
    "inception_model_dir=\"inceptionV3_model/\"\n",
    "if not os.path.exists(inception_model_dir):\n",
    "    os.makedirs(inception_model_dir)\n",
    "\n",
    "train_bottleneck_dir_with_segmentation=\"./tf_files/train_bottlenecks_with_segmentation/\"\n",
    "if not os.path.exists(train_bottleneck_dir_with_segmentation):\n",
    "    os.makedirs(train_bottleneck_dir_with_segmentation)\n",
    "\n",
    "train_bottleneck_dir_without_segmentation=\"./tf_files/train_bottlenecks_without_segmentation/\"\n",
    "if not os.path.exists(train_bottleneck_dir_without_segmentation):\n",
    "    os.makedirs(train_bottleneck_dir_without_segmentation)\n",
    "\n",
    "# it's a better size after a while testing\n",
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "\n",
    "BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'\n",
    "JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'\n",
    "RESIZED_INPUT_TENSOR_NAME = 'ResizeBilinear:0'\n",
    "final_tensor_name = 'final_result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start learning with original images with no segmentation then with segmented images and compare the results\n",
    "# now we will create a function that takes the category name and return the label \n",
    "def read_label(category_name):\n",
    "    arr=category_name.split('_')\n",
    "    category_name=arr[1]\n",
    "    label =  np.zeros(num_classes, dtype=np.float32)\n",
    "    file_read = open(\"categories_names.txt\", \"r\")\n",
    "    labels  = file_read.read().split('\\n')\n",
    "    for i in range(len(labels)):\n",
    "        if category_name == labels[i]:\n",
    "            label[i] = 1.0\n",
    "            return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create this function to read bottlnecks contains the resulted 2048 folat number of the image\n",
    "def load_bottlenecks(Bottleneck_dir):\n",
    "    Bottlenecks = []\n",
    "    labels=[]\n",
    "    counter = 0\n",
    "    index = 0 \n",
    "    for Class in os.listdir(Bottleneck_dir):\n",
    "        class_path = os.path.join(Bottleneck_dir, Class)\n",
    "        for item in os.listdir(class_path):\n",
    "            bottleneck_path = os.path.join ( class_path, item )\n",
    "            with open ( bottleneck_path, 'r' ) as bottleneck_file:\n",
    "                bottleneck_string = bottleneck_file.read ()\n",
    "            bottleneck_values = [float ( x ) for x in bottleneck_string.split ( ',' )]\n",
    "            label = get_label ( Class )\n",
    "            Bottlenecks.append (bottleneck_values  )\n",
    "            labels.append(label)\n",
    "            counter += 1\n",
    "        index += 1\n",
    "\n",
    "    return Bottlenecks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inception graph function\n",
    "# refrence : https://www.programcreek.com/python/example/90293/tensorflow.GraphDef\n",
    "\n",
    "def create_inception_graph():\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        model_filename = os.path.join(inception_model_dir, 'classify_image_graph_def.pb')\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n",
    "          tf.import_graph_def(graph_def, name='', return_elements=[\n",
    "              BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME,\n",
    "              RESIZED_INPUT_TENSOR_NAME]))\n",
    "    return graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Image_lists(image_path):\n",
    "    # load the images for train and store into result dictionary \n",
    "    result = {}\n",
    "    for img in os.listdir(image_path):\n",
    "        training_images = []\n",
    "        for file in os.listdir(os.path.join(image_path,img)):\n",
    "            training_images.append(file)\n",
    "            \n",
    "        #save the label and the names to the dictionary\n",
    "        result[img] = {'dir': img, 'training': training_images}\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file path\n",
    "def get_path(image_lists, label_name, index, image_dir, category):\n",
    "\n",
    "    if label_name not in image_lists:\n",
    "        tf.logging.fatal('Label does not exist %s.', label_name)\n",
    "    label_lists = image_lists[label_name]\n",
    "    if category not in label_lists:\n",
    "        tf.logging.fatal('Category does not exist %s.', category)\n",
    "    category_list = label_lists[category]\n",
    "    if not category_list:\n",
    "        tf.logging.fatal('Label %s has no images in the category %s.', label_name, category)\n",
    "    mod_index = index % len(category_list)\n",
    "    base_name = category_list[mod_index]\n",
    "    sub_dir = label_lists['dir']\n",
    "    full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "    print(full_path)\n",
    "    return full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,bottleneck_tensor):\n",
    "    \n",
    "    image_path = get_path(image_lists, label_name, index, image_dir, category)\n",
    "    if not gfile.Exists(image_path):\n",
    "        tf.logging.fatal('File does not exist %s', image_path)\n",
    "\n",
    "    image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "    try:\n",
    "        print(\"create bottle \", sess.__dict__)\n",
    "        bottleneck_values = sess.run(bottleneck_tensor, {jpeg_data_tensor: image_data})\n",
    "        bottleneck_values = np.squeeze(bottleneck_values)\n",
    "        bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "        \n",
    "        with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "            bottleneck_file.write(bottleneck_string)\n",
    "        print(\"bottleneck file created successfully\")    \n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error during processing file %s' % image_path)\n",
    "        print(e)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, bottleneck_tensor):\n",
    "\n",
    "    if not os.path.exists(bottleneck_dir):\n",
    "        os.makedirs(bottleneck_dir)\n",
    "    bottlenecks = 0\n",
    "    for label_name, label_lists in image_lists.items ():\n",
    "        for category in ['training']:\n",
    "\n",
    "            # get images names in each category\n",
    "            category_list = label_lists[category]\n",
    "\n",
    "            for index, unused_base_name in enumerate(category_list):\n",
    "                # if the bottleneck is already exist load it ,if not create it from the graph\n",
    "                label_lists = image_lists[label_name]\n",
    "                sub_dir = label_lists['dir']\n",
    "                sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n",
    "                if not os.path.exists(sub_dir_path):\n",
    "                    os.makedirs(sub_dir_path)\n",
    "\n",
    "              # create bottleneck path for each image\n",
    "                bottleneck_path = get_path(image_lists, label_name, index, bottleneck_dir, category)\n",
    "                bottleneck_path += '.txt' \n",
    "                if not os.path.exists(bottleneck_path):\n",
    "                    create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess, jpeg_data_tensor, bottleneck_tensor)\n",
    "\n",
    "                with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "                    bottleneck_string = bottleneck_file.read()\n",
    "                hit_error = False\n",
    "                try:\n",
    "                    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "                except ValueError:\n",
    "                    print('Invalid float found, recreating bottleneck')\n",
    "                    hit_error = True\n",
    "\n",
    "                if hit_error:\n",
    "                    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                                       image_dir, category, sess, jpeg_data_tensor,\n",
    "                                       bottleneck_tensor)\n",
    "                with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "                    bottleneck_string = bottleneck_file.read()\n",
    "                    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "\n",
    "                bottlenecks += 1\n",
    "        print ('bottleneck files created {}'.format(str(bottlenecks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the last layer for training\n",
    "def final_training_layer(class_count, final_tensor_name, bottleneck_tensor):\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        bottleneck_input = tf.placeholder_with_default(bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],name='BottleneckInputPlaceholder')\n",
    "\n",
    "        ground_truth_input = tf.placeholder(tf.float32,[None, class_count],name='GroundTruthInput')\n",
    "        layer_name = 'final_training_ops'\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            initial_value = tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, class_count],\n",
    "                                          stddev=0.001)\n",
    "            layer_weights = tf.Variable(initial_value, name='final_weights')\n",
    "\n",
    "        with tf.name_scope('biases'):\n",
    "            layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "  \n",
    "    final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "  \n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth_input, logits=logits)\n",
    "        with tf.name_scope('total'):\n",
    "            cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "  \n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "        train_step = optimizer.minimize(cross_entropy_mean)\n",
    "\n",
    "    return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,final_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evaluation step to test the last layer\n",
    "def evaluation_step(result_tensor, ground_truth_tensor):\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            prediction = tf.argmax(result_tensor, 1)\n",
    "            correct_prediction = tf.equal(prediction, tf.argmax(ground_truth_tensor, 1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return evaluation_step, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_image_dir,train_bottleneck_dir,output_graph_path):\n",
    "    # Building the InceptionV3 graph\n",
    "    graph, bottleneck_tensor, jpeg_data_tensor, resized_image_tensor = (create_inception_graph())\n",
    "    train_image_lists = Create_Image_lists ( train_image_dir )\n",
    "    \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        # Here we cashe bottlenecks on .txt files to use it on training\n",
    "        cache_bottlenecks(sess, train_image_lists, train_image_dir, train_bottleneck_dir, jpeg_data_tensor,bottleneck_tensor)\n",
    "\n",
    "        # Add the new layer that we'll be training.\n",
    "        (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n",
    "        final_tensor) = final_training_layer(num_classes,final_tensor_name, bottleneck_tensor)\n",
    "\n",
    "        # Create the operations we need to evaluate the accuracy of our new layer.\n",
    "        evaluation_step, prediction = evaluation_step(final_tensor, ground_truth_input)\n",
    "        #load trained bottlenecks\n",
    "        train_bottlenecks,train_labels = load_bottlenecks(train_bottleneck_dir)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        #learn the last layer for the number of steps \n",
    "        for step in range(training_steps):\n",
    "            _ = sess.run([ train_step],feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                                     ground_truth_input: train_labels})\n",
    "        \n",
    "            if (step % display_step) == 0 :\n",
    "                train_accuracy, cross_entropy_value = sess.run([evaluation_step, cross_entropy],\n",
    "                feed_dict={bottleneck_input: train_bottlenecks,ground_truth_input: train_labels})\n",
    "                print('Step %d: Train accuracy = %.1f%% , Loss = %f ' % ( step,train_accuracy * 100,\n",
    "                                                                         cross_entropy_value))     \n",
    "        output_graph_def = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), \n",
    "                                                                     [final_tensor_name])\n",
    "        if not os.path.exists(output_graph_path):\n",
    "            os.makedirs(output_graph_path)\n",
    "            \n",
    "        if not os.path.exists(output_graph_path+\"retrained_graph.pb\"):\n",
    "            with gfile.FastGFile(output_graph_path+\"retrained_graph.pb\", 'wb') as f:\n",
    "                f.write(output_graph_def.SerializeToString())\n",
    "            print(\"Retrained graph saved successfully\")\n",
    "\n",
    "            \n",
    "def test(test_image_dir,output_graph_path):\n",
    "    #testing\n",
    "    #load the graph\n",
    "    with tf.gfile.FastGFile(output_graph_path+\"retrained_graph.pb\", 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    #test\n",
    "    print(\"Testing started ...... this may take a while ^_^ \")\n",
    "    with tf.Session() as sess:\n",
    "        correctly_classified = 0\n",
    "        total_images_num=0\n",
    "\n",
    "        for Class in os.listdir ( test_image_dir ):\n",
    "            Label=get_label(Class)\n",
    "            for i in range(len(Label)):\n",
    "                if Label[i]==1:\n",
    "                    label=i\n",
    "            for img in os.listdir ( test_image_dir+Class):\n",
    "                total_images_num+=1\n",
    "                image_path = os.path.join ( test_image_dir+Class, img )\n",
    "                image_data = tf.gfile.FastGFile ( image_path, 'rb' ).read ()\n",
    "                softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "                predictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data})\n",
    "                top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "                pred=top_k[0]\n",
    "                if pred==label:\n",
    "                    correctly_classified+=1\n",
    "    test_acc=(correctly_classified/total_images_num)*100\n",
    "    print('Test accuracy = %.3f%% ' % ( test_acc ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tf_files/train_bottlenecks_without_segmentation/alpine sea holly-35\\image_06984.jpg\n",
      "dataset/alpine sea holly-35\\image_06984.jpg\n",
      "create bottle  {'_graph': <tensorflow.python.framework.ops.Graph object at 0x000001C69EB045F8>, '_opened': False, '_closed': False, '_current_version': 0, '_extend_lock': <unlocked _thread.lock object at 0x000001C6AB085D28>, '_target': b'', '_delete_lock': <unlocked _thread.lock object at 0x000001C6AB085F80>, '_dead_handles': [], '_config': device_count {\n",
      "  key: \"CPU\"\n",
      "  value: 1\n",
      "}\n",
      "device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      "gpu_options {\n",
      "  experimental {\n",
      "  }\n",
      "}\n",
      ", '_add_shapes': False, '_session': <Swig Object of type 'TF_Session *' at 0x000001C6A936C720>, '_default_graph_context_manager': <contextlib._GeneratorContextManager object at 0x000001C6A576A7F0>, '_default_session_context_manager': <contextlib._GeneratorContextManager object at 0x000001C6A576AE80>}\n",
      "Error during processing file dataset/alpine sea holly-35\\image_06984.jpg\n",
      "The Session graph is empty.  Add operations to the graph before calling run().\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tf_files/train_bottlenecks_without_segmentation/alpine sea holly-35\\\\image_06984.jpg.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-e80b6dea7c55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train non segmentation images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m run(train_image_dir_without_segmentation,train_bottleneck_dir_without_segmentation,\n\u001b[1;32m----> 3\u001b[1;33m     output_graph_path_without_segmentation)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-89-62369863836f>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(train_image_dir, train_bottleneck_dir, output_graph_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Here we cashe bottlenecks on .txt files to use it on training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mcache_bottlenecks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_image_lists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_image_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_bottleneck_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjpeg_data_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbottleneck_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Add the new layer that we'll be training.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-003fcc7dbd9c>\u001b[0m in \u001b[0;36mcache_bottlenecks\u001b[1;34m(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, bottleneck_tensor)\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mcreate_bottleneck_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_lists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjpeg_data_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottleneck_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbottleneck_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                     \u001b[0mbottleneck_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbottleneck_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mhit_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tf_files/train_bottlenecks_without_segmentation/alpine sea holly-35\\\\image_06984.jpg.txt'"
     ]
    }
   ],
   "source": [
    "# train non segmentation images\n",
    "run(train_image_dir_without_segmentation,train_bottleneck_dir_without_segmentation,\n",
    "    output_graph_path_without_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
